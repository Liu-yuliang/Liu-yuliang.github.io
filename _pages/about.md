---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi, thank you for your attention. I am Yuliang LiuÔºàÂàòÁéâÊ¢ÅÔºâ. I have been pursuing my Ph.D. at Nanjing University since 2024, and now I am jointly trained at Shanghai Innovation Institute. My supervisor at SII is Professor Zhouhan Lin. My research focuses on

Before this, I learn at Nanjing University under the supervision of Professor Qing Gu and Assistant Professor Zhiwei Jiang. I obtained my Bachelor's degree from Shandong University in 2021, majoring in material science, so I have spent some time paying attention to AI4Science.

# üî• News

- *2025.05*: One paper ([AdaptiveStep](https://arxiv.org/abs/2502.13943)) was accepted by ICML'25.

- *2025.02*: We release [AdaptiveStep](https://arxiv.org/abs/2502.13943), a new method to divide CoT steps with model confidence.

- *2024.09*: We release [LongRecipe](https://arxiv.org/abs/2409.00509), an efficient long context training method for LLM via PI modification & token selection. Welcome to STAR and FORK!



# üìù Publications Ôºàworking in progressÔºâ

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence](https://arxiv.org/abs/2502.13943)

[**Paper**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC)

**Yuliang Liu**<sup>‚Ä†</sup>, Junjie Lu<sup>‚Ä†</sup>, Zhaoling Chen, Chaofeng Qu, Jason Klein Liu, Chonghan Liu, Zefan Cai, Yunhui Xia, Li Zhao, Jiang Bian, Chuheng Zhang<sup>‚Ä°</sup>, Wei Shen<sup>‚Ä°</sup>, Zhouhan Lin<sup>‚Ä°</sup>


[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AP-Adapter: Improving Generalization of Automatic Prompts on Unseen Text-to-Image Diffusion Models](https://proceedings.neurips.cc/paper_files/paper/2024/hash/b2077e6d66da612fcb701589efa9ce88-Abstract-Conference.html)

[**Paper**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC)

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR 2023</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Unsupervised Readability Assessment via Learning from Weak Readability Signals](https://dl.acm.org/doi/abs/10.1145/3539618.3591695)

[**Paper**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC)

</div>
</div>






# üìù Preprints

[LongRecipe: Recipe for Efficient Long Context Generalization in Large Language Models](https://arxiv.org/abs/2409.00509)

[Pyramidkv: Dynamic kv cache compression based on pyramidal information funneling](https://arxiv.org/abs/2406.02069)

[Ml-bench: Large language models leverage open-source libraries for machine learning tasks](https://arxiv.org/abs/2311.09835)


# üéñ Honors and AwardsÔºàworking in progressÔºâ
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2024.09 - now*, PhD Student, Nanjing University & Shanghai Innovation Institute, Shanghai. 
- *2021.09 - 2024.06*,  - , Nanjing University, Nanjing.
- *2017.09 - 2021.06*, Undergraduate, Shandong Univeristy, Jinan. 


